# Server Configuration
PORT=3000
NODE_ENV=development

# OpenAI Configuration (for GPT models)
OPENAI_API_KEY=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
 
OPENAI_MODEL=gpt-4o-mini

# Alternative: Azure OpenAI Configuration
# AZURE_OPENAI_API_KEY=your_azure_key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# Alternative: Anthropic Claude Configuration
# ANTHROPIC_API_KEY=your_anthropic_key
# ANTHROPIC_MODEL=claude-3-opus-20240229

# Alternative: Local LLM Configuration (Ollama, LM Studio, etc.)
# LOCAL_LLM_ENDPOINT=http://localhost:11434/api/generate
# LOCAL_LLM_MODEL=llama2

# Application Settings
MAX_TOKENS=2000
TEMPERATURE=0.7
